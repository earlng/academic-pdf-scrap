{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to take XML files found in the `/xml` directory, and produce a csv output (`output.csv`) that has the following:\n",
    "* Article Title\n",
    "* Impact Statement\n",
    "* Impact Statement Word Count\n",
    "* Impact Statement Citation Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:41: DeprecationWarning: invalid escape sequence \\.\n",
      "<>:43: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:41: DeprecationWarning: invalid escape sequence \\.\n",
      "<>:43: DeprecationWarning: invalid escape sequence \\w\n",
      "<ipython-input-5-801f1344c23f>:41: DeprecationWarning: invalid escape sequence \\.\n",
      "  impact_statement_number_of_sentences=len(re.split(\"\\.|\\?|!\", impact_statement_text))-1\n",
      "<ipython-input-5-801f1344c23f>:43: DeprecationWarning: invalid escape sequence \\w\n",
      "  paper_identifier = re.search(\"(\\w*)(-Paper)\", filename)\n"
     ]
    }
   ],
   "source": [
    "#XML files that are already genereated via PDFx are assumed to be in a directory \"xml\"\n",
    "\n",
    "directory=\"xml\"\n",
    "impact_dict={\"title\":[], \"paper identifier\":[], \"paper link\":[], \"impact statement\":[], \"impact title\":[], \"impact statement word count\":[], \"impact statement sentence count\":[], \"citation count\":[],\n",
    "            \"has positive\":[], \"has negative\":[], \"has opt out\":[], \"has NA\":[]}\n",
    "\n",
    "#initialize citations_dict, which is a separate dictionary to be generated as a separate CSV file (citation.csv)\n",
    "citation_dict={\"paper title\":[],\"paper id\":[],\"citation\":[]}\n",
    "\n",
    "#loops through the directory, and appends the relevant information to impact_dict, which will be appended to the dataframe later\n",
    "for filename in os.listdir(directory):\n",
    "    #to exclude \"sample.xml\"\n",
    "    if filename.endswith(\".pdfx.xml\"):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        tree = ET.parse(full_path)\n",
    "        root = tree.getroot()\n",
    "        #get article title\n",
    "        #initialize a list of citations for this document\n",
    "        citation_ref = []\n",
    "        for section in root[1][0][0]:\n",
    "            if section.tag==\"article-title\":\n",
    "                title = section.text\n",
    "        for section in root[1][1]:\n",
    "            citations = 0\n",
    "            signal = 0\n",
    "            for child in section:\n",
    "                if signal == 1 :\n",
    "                    #print(section.text)\n",
    "                    #broader_dict[filename] = section.text\n",
    "                    #loop through any xrefs to count for citations\n",
    "                    for xref in child:\n",
    "                        #narrow down xref citations to bibliography references\n",
    "                        if xref.tag == \"xref\" and xref.attrib['ref-type'] == \"bibr\":\n",
    "                            #use \"rid\" as the identifier, so we come out of this with a list of references\n",
    "                            citation_ref.append(xref.attrib['rid'])\n",
    "                            citations +=1\n",
    "                    #itertext will make sure that if there are any tags within the section, we still get the whole thing.\n",
    "                    impact_statement_text=''.join(child.itertext())\n",
    "                    impact_statement_number_of_words=len(impact_statement_text.split())\n",
    "                    #add count for setences using delimeters of \".\", \"?\", and \"!\"\n",
    "                    impact_statement_number_of_sentences=len(re.split(\"\\.|\\?|!\", impact_statement_text))-1\n",
    "                    #will identify the hash based off of this pattern \"86d7c8a08b4aaa1bc7c599473f5dddda-Paper.pdfx.xml\"\n",
    "                    paper_identifier = re.search(\"(\\w*)(-Paper)\", filename)\n",
    "                    #check if \"positive\" is in the statement\n",
    "                    has_positive = \"True\" if \"positive\" in impact_statement_text.lower() else \"False\"\n",
    "                    #check if \"negative\" is in the statement\n",
    "                    has_negative = \"True\" if \"negative\" in impact_statement_text.lower() else \"False\"\n",
    "                    #check if it has the NeurIPS opt-out phrase\n",
    "                    has_opt_out = \"True\" if \"this work does not present any foreseeable societal consequence\" in impact_statement_text.lower() else \"False\"\n",
    "                    #check if it has \"Not Applicable\"\n",
    "                    has_NA = \"True\" if \"not applicable\" in impact_statement_text.lower() else \"False\"\n",
    "                    #add everything to the dictionary\n",
    "                    impact_dict[\"impact title\"].append(impact_statement_title)\n",
    "                    impact_dict[\"impact statement\"].append(impact_statement_text)\n",
    "                    impact_dict[\"impact statement word count\"].append(impact_statement_number_of_words)\n",
    "                    impact_dict[\"impact statement sentence count\"].append(impact_statement_number_of_sentences)\n",
    "                    impact_dict[\"citation count\"].append(citations)\n",
    "                    impact_dict[\"title\"].append(title)\n",
    "                    impact_dict[\"paper identifier\"].append(paper_identifier[1])\n",
    "                    impact_dict[\"paper link\"].append(\"https://proceedings.neurips.cc/paper/2020/file/\" + paper_identifier[1] + \"-Paper.pdf\")\n",
    "                    impact_dict[\"has positive\"].append(has_positive)\n",
    "                    impact_dict[\"has negative\"].append(has_negative)\n",
    "                    impact_dict[\"has opt out\"].append(has_opt_out)\n",
    "                    impact_dict[\"has NA\"].append(has_NA)\n",
    "                    signal = 0\n",
    "                    #print(citation_ref)\n",
    "                #focus on heading\n",
    "                if \"impact\" in str(child.text).lower() and child.tag == \"h1\":\n",
    "                    #print(\"It has a Broader Impact!\")\n",
    "                    #log the title of the broader impact statement\n",
    "                    impact_statement_title = child.text\n",
    "                    signal=1\n",
    "                elif str(child.text).lower() == \"broader impact\" and child.tag == \"h1\":\n",
    "                    impact_statement_title = child.text\n",
    "                    signal=1\n",
    "                elif str(child.text).lower() == \"broader impacts\" and child.tag == \"h1\":\n",
    "                    impact_statement_title = child.text\n",
    "                    signal=1\n",
    "            #identify the bibliography\n",
    "            if section.attrib[\"class\"] == \"DoCO:Bibliography\":\n",
    "                #loop through the bibliography section, but we really only want one part\n",
    "                for references in section:\n",
    "                    if references.attrib[\"class\"] == \"DoCO:BiblioGraphicReferenceList\":\n",
    "                        #loop through all the entries in the reference list\n",
    "                        for citation in references:\n",
    "                            #the try statement is because if the bibliography is across multiple pages, there will be entries with no \"rid\", so we account for that with a keyerror.\n",
    "                            try:\n",
    "                                #check if the citation is in the citation_ref we established earlier\n",
    "                                if citation.attrib[\"rid\"] in citation_ref:\n",
    "                                    citation_dict[\"paper title\"].append(title)\n",
    "                                    citation_dict[\"paper id\"].append(paper_identifier[1])\n",
    "                                    citation_dict[\"citation\"].append(citation.text)\n",
    "                            except KeyError:\n",
    "                                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataframe for the output from the dictionary\n",
    "impact_statements =pd.DataFrame.from_dict(impact_dict)\n",
    "\n",
    "#create the dataframe for the citations from the dictionary\n",
    "total_citations =pd.DataFrame.from_dict(citation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the CSV file from the dataframe\n",
    "\n",
    "impact_statements.to_csv(\"output.csv\",index=False)\n",
    "\n",
    "#generate the CSV file for the citations\n",
    "total_citations.to_csv(\"citations.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based off of [this](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0) guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_statements['processed'] = impact_statements['content'].map(lambda x: re.sub('[^a-zA-Z0-9 ]', '', x))\n",
    "impact_statements['processed'] = impact_statements['processed'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a wordcloud\n",
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(impact_statements['processed'].values))\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function\n",
    "def plot_10_most_common_words(count_data, count_vectorizer):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n",
    "    words = [w[0] for w in count_dict]\n",
    "    counts = [w[1] for w in count_dict]\n",
    "    x_pos = np.arange(len(words)) \n",
    "    \n",
    "    plt.figure(2, figsize=(15, 15/1.6180))\n",
    "    plt.subplot(title='10 most common words')\n",
    "    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "    sns.barplot(x_pos, counts, palette='husl')\n",
    "    plt.xticks(x_pos, words, rotation=90) \n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('counts')\n",
    "    plt.show()\n",
    "\n",
    "# Initialise the count vectorizer with the English stop words\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "# Fit and transform the processed titles\n",
    "count_data = count_vectorizer.fit_transform(impact_statements['processed'])\n",
    "# Visualise the 10 most common words\n",
    "plot_10_most_common_words(count_data, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    " \n",
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "# Tweak the two parameters below\n",
    "number_topics = 4\n",
    "number_words = 10\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda.fit(count_data)\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "LDAvis_data_filepath = os.path.join('./ldavis_prepared_'+str(number_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "\n",
    "#if 1 == 1:\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda, count_data, count_vectorizer)\n",
    "\n",
    "with open(LDAvis_data_filepath, 'wb') as f:\n",
    "    pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, \"rb\") as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(LDAvis_prepared, './ldavis_prepared_'+ str(number_topics) +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
